{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8106e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7465643c",
   "metadata": {},
   "source": [
    "#### 1st pass finetune - Mattergen XRD\n",
    "- Dataset Source: [Mattergen Alex-MP-20](https://github.com/microsoft/mattergen/tree/main/data-release/alex-mp)\n",
    "  - Columns: Database (manual) \n",
    "  - Reduced Formula (Source)\n",
    "  - CIF (pmg - Cifwriter with symprec 0.1)\n",
    "  - XRD 'Condition Vector' (with [_calculate_XRD.py](_utils/_preprocessing/_calculate_XRD.py))\n",
    "    - pmg - XRDCalculator(wavelength=\"CuKa\")\n",
    "    - top 20 most intense peaks selected ($2\\theta$ and int)\n",
    "    - Normalisations\n",
    "      - $2\\theta$ min-max for 0,90\n",
    "      - intensities min-max for 0,100\n",
    "- Deduplicated\n",
    "- Cleaned for CIF augmentation\n",
    "  -  Note: I didnt filter to context length here because it was not implemented yet, but filter to context was flagged as True during model training which effectively does the same thing (less efficient)\n",
    "- dataset pushed to HuggingFace as: c-bone/mattergen_XRD (90:10 train/valid sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e4393",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node=2 _train.py --config '_config_files/training/conditional/xrd_studies/mattergen_XRD-slider.jsonc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98df9376",
   "metadata": {},
   "source": [
    "#### 2nd pass finetune - COD XRD\n",
    "- Dataset Source: [COD hkl data](https://www.crystallography.net/hkl/)\n",
    "  - Columns: Database (manual) \n",
    "  - Reduced Formula (automated extraction from source)\n",
    "  - CIF\n",
    "    - automated extraction of material id from COD source\n",
    "    - converted to structure using pmg COD.get_structure_by_id\n",
    "    - Cifwriter with symprec 0.1 for CIF\n",
    "    - note: this was done because alot of COD cifs arent in clean standard format. Pymatgen already did a big job of cleaning them up so we dont need to reinvent the wheel and take CIF data straight from source.\n",
    "  - XRD data\n",
    "    - For every Material ID that has experimental hkl data and associated intensities, we extract it\n",
    "    - Then:\n",
    "      1. Calculate d_hkl from crystal structure.lattice.d_hkl([h, k, l])\n",
    "      2. Use Bragg's law: sin($\\theta$) = $\\lambda$/($2$ × d_hkl)\n",
    "      3. Find $\\theta$ = arcsin($\\lambda$/($2$ × d_hkl))\n",
    "      4. Convert to degrees: $2\\theta$ = $2$ × $\\theta$ × (180/$\\pi$)\n",
    "    - Where:\n",
    "      - $\\lambda$: X-ray wavelength ($1.5406$ $\\AA$ for Cu K$\\alpha$)\n",
    "      - d_hkl: d-spacing for the (hkl) planes\n",
    "      - $\\theta$: Bragg angle\n",
    "    - Created 'Condition Vector'\n",
    "      - top 20 most intense peaks selected ($2\\theta$ and int)\n",
    "      - Normalisations\n",
    "        - $2\\theta$ min-max for 0,90\n",
    "        - intensities min-max for 0,100\n",
    "  - Filtered out all hydrocarbons\n",
    "    - symbols = struct.symbol_set\n",
    "    - if \"C\" in symbols and \"H\" in symbols, remove it\n",
    "  - Then cleaning for CIF augmentation\n",
    "    - set --make_disordered_ordered flag\n",
    "      - Makes every occupancy exactly integer if occupancy is int $\\pm 0.05$. Element set needs to be exactly preserved or structure discarded.\n",
    "    - Filtered to 1024 contect length\n",
    "  - Pushed to HuggingFace as c-bone/COD_XRD_small_nohc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64bf4d",
   "metadata": {},
   "source": [
    "### Training\n",
    "> **Note**: Here the hyperparamters change compared to regular finetuning because its 2nd pass. Backbone learning rates were set to decay from $5\\times10^{-8}$ to $5\\times10^{-10}$, while the learning rates for the newly initialised conditioning parameters were set 100 times higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259b2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_preprocessing/_save_dataset_to_HF.py \\\n",
    "    --input_parquet 'HF-databases/COD_dev/COD_xrd_clean_nohc_small.parquet' \\\n",
    "    --output_parquet 'HF-databases/COD_XRD_small_nohc_full.parquet' \\\n",
    "    --valid_size 0.000 \\\n",
    "    --test_size 0.125 \\\n",
    "    --save_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912325c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!torchrun --nproc_per_node=2 _train.py --config '_config_files/training/conditional/xrd_studies/COD_XRD_small-slider-opt.jsonc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf948d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reference file from test split\n",
    "import pandas as pd\n",
    "df = pd.read_parquet('HF-databases/COD_XRD_small_nohc_full.parquet')\n",
    "df_test = df[df['Split'] == 'test'].copy()\n",
    "df_test.to_parquet('_artifacts/cod-xrd/cod-test_ref.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad8273",
   "metadata": {},
   "source": [
    "### Generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1679014",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/make_prompts.py \\\n",
    "    --HF_dataset 'c-bone/COD_XRD_small_nohc' \\\n",
    "    --split 'test' \\\n",
    "    --automatic \\\n",
    "    --output_parquet '_artifacts/cod-xrd/cod-test_prompts.parquet' \\\n",
    "    --level 'level_3' \\\n",
    "    --condition_columns 'Condition Vector'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dcf8e8",
   "metadata": {},
   "source": [
    "#### Generate materials using 2-pass finetuning and XRD information (Repeated 3x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f9744",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/generate_CIFs.py --config '_config_files/generation/conditional/xrd_studies/cod-xrd_eval.jsonc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f3e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/postprocess.py \\\n",
    "    --input_parquet '_artifacts/cod-xrd/cod-ft-20perp-test_gen.parquet' \\\n",
    "    --output_parquet '_artifacts/cod-xrd/cod-ft-20perp-test_post.parquet' \\\n",
    "    --num_workers 32 \\\n",
    "    --column_name 'Generated CIF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_metrics/XRD_metrics.py \\\n",
    "    --input_parquet '_artifacts/cod-xrd/cod-ft-20perp-test_post.parquet' \\\n",
    "    --num_gens 20 \\\n",
    "    --ref_parquet '_artifacts/cod-xrd/cod-test_ref.parquet' \\\n",
    "    --output_parquet '_artifacts/cod-xrd/cod-ft-20perp-test_metrics.parquet' \\\n",
    "    --num_workers 32 \\\n",
    "    --validity_check \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70990762",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_metrics/XRD_metrics.py \\\n",
    "    --input_parquet '_artifacts/cod-xrd/cod-ft-20perp-test_post.parquet' \\\n",
    "    --num_gens 1 \\\n",
    "    --ref_parquet '_artifacts/cod-xrd/cod-test_ref.parquet' \\\n",
    "    --output_parquet '_artifacts/cod-xrd/cod-ft-1perp-test_metrics.parquet' \\\n",
    "    --num_workers 32 \\\n",
    "    --validity_check \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbb898",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_metrics/XRD_metrics.py \\\n",
    "    --input_parquet '_artifacts/cod-xrd/cod-ft-20perp-test_post.parquet' \\\n",
    "    --num_gens 1 \\\n",
    "    --ref_parquet '_artifacts/cod-xrd/cod-test_ref.parquet' \\\n",
    "    --output_parquet '_artifacts/cod-xrd/cod-ft-1rand-test_metrics.parquet' \\\n",
    "    --num_workers 32 \\\n",
    "    --validity_check \"none\"\\\n",
    "    --sort_gens \"random\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe535c2d",
   "metadata": {},
   "source": [
    "#### Generate materials using 2-pass finetuning (Mattergen XRD + COD XRD nohc) but no XRD information fed during inference (repeated 3x)\n",
    "\n",
    "> **Note**: replaced the condition_vector column in the prompt df made above with a series of [-100] missing values meaning no XRD information is fed during generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba949a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f390871",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/generate_CIFs.py --config '_config_files/generation/conditional/xrd_studies/cod-xrd-uncond_eval.jsonc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b11d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/postprocess.py \\\n",
    "    --input_parquet '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-20perp-test_gen.parquet' \\\n",
    "    --output_parquet '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-20perp-test_post.parquet' \\\n",
    "    --num_workers 32 \\\n",
    "    --column_name 'Generated CIF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_metrics/XRD_metrics.py \\\n",
    "    --input_parquet '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-20perp-test_post.parquet' \\\n",
    "    --num_gens 20 \\\n",
    "    --ref_parquet '_artifacts/cod-xrd/perp-repeats/cod-test_ref.parquet' \\\n",
    "    --output_parquet '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-20perp-test_metrics.parquet' \\\n",
    "    --num_workers 32 \\\n",
    "    --validity_check \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ba282",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_metrics/XRD_metrics.py \\\n",
    "    --input_parquet '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-20perp-test_post.parquet' \\\n",
    "    --num_gens 1 \\\n",
    "    --ref_parquet '_artifacts/cod-xrd/perp-repeats/cod-test_ref.parquet' \\\n",
    "    --output_parquet '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-1perp-test_metrics.parquet' \\\n",
    "    --num_workers 32 \\\n",
    "    --validity_check \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40127759",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1perp_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-1perp-test_metrics.parquet'\n",
    "metrics_1perp_v2_parquet= '_artifacts/cod-xrd/perp-repeats/cod-ft-1perp-v2-test_metrics.parquet'\n",
    "metrics_1perp_v3_parquet= '_artifacts/cod-xrd/perp-repeats/cod-ft-1perp-v3-test_metrics.parquet'\n",
    "metrics_20perp_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-20perp-test_metrics.parquet'\n",
    "metrics_20perp_v2_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-20perp-v2-test_metrics.parquet'\n",
    "metrics_20perp_v3_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-20perp-v3-test_metrics.parquet'\n",
    "metrics_uncond_1perp_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-1perp-test_metrics.parquet'\n",
    "metrics_uncond_1perp_v2_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-1perp-v2-test_metrics.parquet'\n",
    "metrics_uncond_1perp_v3_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-1perp-v3-test_metrics.parquet'\n",
    "metrics_uncond_20perp_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-20perp-test_metrics.parquet'\n",
    "metrics_uncond_20perp_v2_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-20perp-v2-test_metrics.parquet'\n",
    "metrics_uncond_20perp_v3_parquet = '_artifacts/cod-xrd/perp-repeats/cod-ft-uncond-20perp-v3-test_metrics.parquet'\n",
    "\n",
    "\n",
    "# make a table with all the results\n",
    "import __init__\n",
    "from _utils import get_metrics_xrd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "paths = {\n",
    "    'cond-20perp': metrics_20perp_parquet,\n",
    "    'cond-20perp-v2': metrics_20perp_v2_parquet,\n",
    "    'cond-20perp-v3': metrics_20perp_v3_parquet,\n",
    "    'cond-1perp': metrics_1perp_parquet,\n",
    "    'cond-1perp-v2': metrics_1perp_v2_parquet,\n",
    "    'cond-1perp-v3': metrics_1perp_v3_parquet,\n",
    "    'uncond-20perp': metrics_uncond_20perp_parquet,\n",
    "    'uncond-20perp-v2': metrics_uncond_20perp_v2_parquet,\n",
    "    'uncond-20perp-v3': metrics_uncond_20perp_v3_parquet,\n",
    "    'uncond-1perp': metrics_uncond_1perp_parquet,\n",
    "    'uncond-1perp-v2': metrics_uncond_1perp_v2_parquet,\n",
    "    'uncond-1perp-v3': metrics_uncond_1perp_v3_parquet\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for names, path in paths.items():\n",
    "    df = pd.read_parquet(path)\n",
    "    metrics_result = get_metrics_xrd(df, n_test=198, only_matched=False, verbose=False)\n",
    "    results[names] = metrics_result\n",
    "        \n",
    "# Create final table with all results\n",
    "final_table = pd.DataFrame.from_dict(results, orient='index')\n",
    "final_table.to_parquet('_artifacts/cod-xrd/cod-ft-vs-uncond-all-results.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c420b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "final_table = pd.read_parquet('_artifacts/cod-xrd/cod-ft-vs-uncond-all-results.parquet')\n",
    "\n",
    "base_conditions = {}\n",
    "for index in final_table.index:\n",
    "    if '-v2' in index:\n",
    "        base_name = index.replace('-v2', '')\n",
    "    elif '-v3' in index:\n",
    "        base_name = index.replace('-v3', '')\n",
    "    else:\n",
    "        base_name = index\n",
    "    \n",
    "    if base_name not in base_conditions:\n",
    "        base_conditions[base_name] = []\n",
    "    base_conditions[base_name].append(index)\n",
    "\n",
    "# averaged results with standard error between the 3 runs\n",
    "averaged_results = {}\n",
    "stderr_results = {}\n",
    "for base_name, variants in base_conditions.items():\n",
    "    variant_data = []\n",
    "    for variant in variants:\n",
    "        if variant in final_table.index:\n",
    "            variant_data.append(final_table.loc[variant])\n",
    "    \n",
    "    if variant_data:\n",
    "        data_df = pd.concat(variant_data, axis=1)\n",
    "        averaged_results[base_name] = data_df.mean(axis=1)\n",
    "        stderr_results[base_name] = data_df.std(axis=1) / np.sqrt(len(variant_data))\n",
    "\n",
    "averaged_table = pd.DataFrame.from_dict(averaged_results, orient='index')\n",
    "stderr_table = pd.DataFrame.from_dict(stderr_results, orient='index')\n",
    "\n",
    "formatted_table = pd.DataFrame(index=averaged_table.index, columns=averaged_table.columns, dtype=object)\n",
    "for col in averaged_table.columns:\n",
    "    for idx in averaged_table.index:\n",
    "        mean_val = averaged_table.loc[idx, col]\n",
    "        stderr_val = stderr_table.loc[idx, col]\n",
    "        if pd.isna(stderr_val) or stderr_val == 0:\n",
    "            formatted_table.loc[idx, col] = f\"{mean_val:.3f}\"\n",
    "        else:\n",
    "            formatted_table.loc[idx, col] = f\"{mean_val:.3f} (±{stderr_val:.3f})\"\n",
    "\n",
    "formatted_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdba1ef",
   "metadata": {},
   "source": [
    "> Note: the results here differ very slightly from the plots in the paper, because those plots calculate R^2 and MAE over all of the rows in the 3 runs (concatenated results), whereas here its the average between the results of each run as a whole and the associated stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a7475b",
   "metadata": {},
   "source": [
    "### Testing on some real data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399e8f3",
   "metadata": {},
   "source": [
    "- Had the chance to get given some XRD data calculated by a group. It was calculated for brookite, anatase and rutiile poolymorphs of TiO2\n",
    "- Anatase and rutile were seen during training and finetuning (in pretrain data and the mattergen xrd 1st pass finetune dataset), brookite was not\n",
    "- Can the model generate the correct structures for experimental XRDs for materials seen in training, and one unseen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8e985",
   "metadata": {},
   "source": [
    "1. First we make a dataset with the true structures as per their materials project structures\n",
    "2. To this we add a prompt for each of the structures\n",
    "3. And a condition vector as per below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeabb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__\n",
    "from _utils import process_xrd_to_condition_vector\n",
    "\n",
    "anatase_raw_data = \"\"\"2θ [°] Cu\tIntensity\n",
    "25.281 100.0\n",
    "36.947 10.0\n",
    "37.801 20.0\n",
    "38.576 10.0\n",
    "48.050 35.0\n",
    "53.891 20.0\n",
    "55.062 20.0\n",
    "62.121 4.0\n",
    "62.690 14.0\n",
    "68.762 6.0\n",
    "70.311 6.0\n",
    "74.031 2.0\n",
    "75.032 10.0\n",
    "76.020 4.0\n",
    "80.727 2.0\n",
    "82.139 2.0\n",
    "82.662 6.0\n",
    "83.149 4.0\n",
    "83.221 2.0\n",
    "\"\"\"\n",
    "\n",
    "rutile_raw_data = \"\"\"2θ [°] Cu\tIntensity\n",
    "27.447 100.0\n",
    "36.086 50.0\n",
    "39.188 8.0\n",
    "41.226 25.0\n",
    "44.052 10.0\n",
    "54.323 60.0\n",
    "56.642 20.0\n",
    "62.742 10.0\n",
    "64.040 10.0\n",
    "65.480 2.0\n",
    "69.010 20.0\n",
    "69.790 12.0\n",
    "72.410 2.0\n",
    "74.411 1.0\n",
    "76.510 4.0\n",
    "79.822 2.0\n",
    "82.335 6.0\n",
    "84.260 4.0\n",
    "87.464 2.0\n",
    "89.557 8.0\"\"\"\n",
    "\n",
    "brookite_raw_data = \"\"\"2θ [°] Cu\tIntensity\n",
    "25.35 100.0\n",
    "25.69 77.71\n",
    "30.81 97.23\n",
    "36.24 23.86\n",
    "37.28 17.77\n",
    "37.96 7.41\n",
    "40.16 14.94\n",
    "42.33 15.5\n",
    "46.07 19.95\n",
    "48.03 32.31\n",
    "49.16 20.2\n",
    "54.22 22.63\n",
    "55.24 31.92\n",
    "57.14 15.52\n",
    "62.08 11.59\n",
    "63.41 7.68\n",
    "63.69 10.48\n",
    "64.98 13.99\n",
    "65.94 8.26\n",
    "70.44 9.04\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Test the function\n",
    "anatase = process_xrd_to_condition_vector(anatase_raw_data)\n",
    "rutile = process_xrd_to_condition_vector(rutile_raw_data)\n",
    "brookite = process_xrd_to_condition_vector(brookite_raw_data)\n",
    "\n",
    "print(anatase)\n",
    "print(rutile)\n",
    "print(brookite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cd57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_path = '_artifacts/cod-xrd/amil/amil-TiO2-nosc-nosg_ref_prompts.parquet'\n",
    "\n",
    "df = pd.read_parquet(df_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8ac55",
   "metadata": {},
   "source": [
    "> Note: I added the condition vector to a dataframe where I stored prompts,true CIF of material, and some information for the experiment. We can use this as both prompt and ref dfs because it contains all the relevant columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852a1b9e",
   "metadata": {},
   "source": [
    "Here we want to probe a few things, can we recover structues from XRD data sent to us by a group we are collaborating with? for 3 different XRD polymorphs. 2 of them were seen in training sets, though neither were in the experimental finetuning set (rutile, anatase), and one of them hasnt been seen at all (training or finetuning).\n",
    "\n",
    "We want to see if we can recover the structures from various possible experimental (their composition), sometimes we have their spacegroup (comp + spacegroup), sometimes we dont really know the composition, so is the model able to match to the material when prompted with the composition of its supercell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04897f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff27c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each of the 4 split files\n",
    "prompt_files = [\n",
    "    'amil-TiO2-nosc-nosg_ref_prompts.parquet',\n",
    "    'amil-TiO2-sc-nosg_ref_prompts.parquet', \n",
    "    'amil-TiO2-nosc-sg_ref_prompts.parquet',\n",
    "    'amil-TiO2-sc-sg_ref_prompts.parquet'\n",
    "]\n",
    "\n",
    "config_files = [\n",
    "    '_config_files/generation/conditional/xrd_studies/amil/cod-amil-xrd-nosc-nosg_eval.jsonc',\n",
    "    '_config_files/generation/conditional/xrd_studies/amil/cod-amil-xrd-sc-nosg_eval.jsonc',\n",
    "    '_config_files/generation/conditional/xrd_studies/amil/cod-amil-xrd-nosc-sg_eval.jsonc', \n",
    "    '_config_files/generation/conditional/xrd_studies/amil/cod-amil-xrd-sc-sg_eval.jsonc'\n",
    "]\n",
    "\n",
    "output_gen_files = [\n",
    "    'amil-TiO2-nosc-nosg_gen.parquet',\n",
    "    'amil-TiO2-sc-nosg_gen.parquet',\n",
    "    'amil-TiO2-nosc-sg_gen.parquet',\n",
    "    'amil-TiO2-sc-sg_gen.parquet'\n",
    "]\n",
    "output_metrics_files = [\n",
    "    'amil-TiO2-nosc-nosg_metrics.parquet',\n",
    "    'amil-TiO2-sc-nosg_metrics.parquet',\n",
    "    'amil-TiO2-nosc-sg_metrics.parquet',\n",
    "    'amil-TiO2-sc-sg_metrics.parquet'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, (prompt_file, config_file, output_file) in enumerate(zip(prompt_files, config_files, output_gen_files)):\n",
    "    print(f\"\\nProcessing {i+1}/4: {prompt_file}\")\n",
    "    \n",
    "    # Generate CIFs\n",
    "    !python _utils/_generating/generate_CIFs.py --config '{config_file}'\n",
    "    \n",
    "    # Postprocess\n",
    "    !python _utils/_generating/postprocess.py \\\n",
    "        --input_parquet '_artifacts/cod-xrd/amil/{output_file}' \\\n",
    "        --output_parquet '_artifacts/cod-xrd/amil/{output_file}' \\\n",
    "        --num_workers 32 \\\n",
    "        --column_name 'Generated CIF'\n",
    "\n",
    "print(\"\\nGeneration and postprocessing complete for all files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffabc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running XRD metrics for all 4 generated files...\")\n",
    "\n",
    "\n",
    "for i, (gen_file, prompt_file, metrics_file) in enumerate(zip(output_gen_files, prompt_files, output_metrics_files)):\n",
    "    print(f\"\\nCalculating metrics for {i+1}/4: {gen_file}\")\n",
    "    \n",
    "    !python _utils/_metrics/XRD_metrics.py \\\n",
    "        --input_parquet '_artifacts/cod-xrd/amil/{gen_file}' \\\n",
    "        --num_gens 20 \\\n",
    "        --ref_parquet '_artifacts/cod-xrd/amil/{prompt_file}' \\\n",
    "        --output_parquet '_artifacts/cod-xrd/amil/{metrics_file}' \\\n",
    "        --num_workers 4 \\\n",
    "        --validity_check \"none\"\n",
    "\n",
    "print(\"\\nXRD metrics calculation complete for all files!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f837f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all the 4 files, make a table with all the results\n",
    "import pandas as pd\n",
    "import __init__\n",
    "from _utils import get_metrics_xrd\n",
    "\n",
    "output_metrics_files = [\n",
    "    'amil-TiO2-nosc-nosg_metrics.parquet',\n",
    "    'amil-TiO2-sc-nosg_metrics.parquet',\n",
    "    'amil-TiO2-nosc-sg_metrics.parquet',\n",
    "    'amil-TiO2-sc-sg_metrics.parquet'\n",
    "]\n",
    "\n",
    "# concatenate all the metrics files into one dataframe\n",
    "all_metrics = pd.concat([pd.read_parquet(f'_artifacts/cod-xrd/amil/{f}') for f in output_metrics_files], ignore_index=True)\n",
    "all_metrics\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystallmv2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
