{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to show example preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we go to correct directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigated to package root: /home/cyprien/CrystaLLMv2_PKV\n",
      "Added package root to Python path\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import __init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['material_id', 'space_group', 'chemical_system', 'num_sites',\n",
      "       'energy_above_hull', 'dft_band_gap', 'dft_bulk_modulus',\n",
      "       'dft_mag_density', 'hhi_score', 'ml_bulk_modulus', 'Database',\n",
      "       'Reduced Formula', 'CIF', 'ALIGNN_BG', 'Density (g/cm^3)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('/home/cyprien/Data_Gen/datasets_dev/mattergen_props.parquet')\n",
    "# show column names\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the dataframe with above columns, lets say we want to make the Mattergen Density dataset\n",
    "\n",
    "Columns you need:\n",
    "- For unconditional training (just structure prediction). You will need symmetrised CIFs (can generate from pymatgen for a structure), Reduced Formula for each CIF, and prefereably their material id's if they come from a database\n",
    "- For conditional training. For each CIF, label it with a functional property value (like density - here also taken from pymatgen calculators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st we deduplicate, eg if there are structures with same formula and space group, only keep one with lowest volume per formula unit (vpfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_preprocessing/_deduplicate.py \\\n",
    "    --input_file '/home/cyprien/Data_Gen/datasets_dev/mattergen_props.parquet' \\\n",
    "    --output_parquet 'test_dedup.parquet' \\\n",
    "    --property_columns \"['Density (g/cm^3)', 'energy_above_hull']\" \\\n",
    "    --filter_na_columns \"['Density (g/cm^3)', 'energy_above_hull']\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we 'clean' or do data augmentation. For the CIFs this means making the format standardised for training, and for the properties we want to normalise their values to ensure training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_preprocessing/_cleaning.py \\\n",
    "    --input_parquet test_dedup.parquet \\\n",
    "    --output_parquet test_clean.parquet \\\n",
    "    --property_columns \"['Density (g/cm^3)', 'energy_above_hull']\" \\\n",
    "    --property1_normaliser \"linear\" \\\n",
    "    --property2_normaliser \"linear\" \\\n",
    "    --num_workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we save our dataset to Huggingface. At this point we're pretty much ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_preprocessing/_save_dataset_to_HF.py \\\n",
    "    --input_parquet 'test_clean.parquet' \\\n",
    "    --output_parquet 'upload_test.parquet' \\\n",
    "    --valid_size 0.1 \\\n",
    "    --test_size 0 \\\n",
    "    --save_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: If for some reason you wish to change the tokenizer, it can be done and tested with this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_preprocessing/_save_tokenizer_to_HF.py \\\n",
    "    --vocab_file '_utils/_tokenizer_utils/vocabulary.json' \\\n",
    "    --spacegroups_file '_utils/_tokenizer_utils/spacegroups.txt' \\\n",
    "    --path 'HF-cif-tokenizer' \\\n",
    "    --hub_path 'c-bone/cif-tokenizer' \\\n",
    "    --push_to_hub \\\n",
    "    --testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystallmv2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
