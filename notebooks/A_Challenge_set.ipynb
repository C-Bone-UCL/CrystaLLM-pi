{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbbaf3b3",
   "metadata": {},
   "source": [
    "### Imports etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8370b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import __init__\n",
    "\n",
    "from _utils import build_challenge_dataframe, filter_df_to_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dcf948",
   "metadata": {},
   "source": [
    "### Pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c196259",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "- Dataset: LeMatBulkUnique structures (April 2025)\n",
    "  - Database (Material ID), Reduced Formula, CIF\n",
    "- Deduplicated\n",
    "- Cleaned for CIF augmentation\n",
    "- Pushed to Huggingface as c-bone/lematerial_clean\n",
    "\n",
    "#### **Warning**: Pretraining takes extremely long (3 weeks on 3 24GB GPUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039ad776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained on 2 GPUs\n",
    "!torchrun --nproc_per_node=2 _train.py \\\n",
    "    --config '_config_files/training/unconditional/lematerial-small.jsonc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30356b",
   "metadata": {},
   "source": [
    "### Fetching Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3459f0cb",
   "metadata": {},
   "source": [
    "Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba29609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load challenge_set_v1.zip from CrystaLLM\n",
    "with open('challenge_set_v1.zip', 'rb') as f:\n",
    "    import zipfile\n",
    "    with zipfile.ZipFile(f, 'r') as zip_ref:\n",
    "        zip_ref.extractall('challenge_set_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad6828",
   "metadata": {},
   "source": [
    "Turn it into a dataframe. We need the CIF column and the Material ID column\n",
    "> Material ID serves as a unique identifier for each struct needed to assess structure recovery capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a655bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_challenge_dataframe(\n",
    "    'artifacts/challenge_set/files',\n",
    "    'artifacts/challenge_set/true_structs.parquet'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7087425",
   "metadata": {},
   "source": [
    "### Making the Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929f27b8",
   "metadata": {},
   "source": [
    "Augment the CIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3696da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_preprocessing/_cleaning.py \\\n",
    "    --input_parquet 'artifacts/challenge_set/true_structs.parquet' \\\n",
    "    --output_parquet 'artifacts/challenge_set/clean.parquet' \\\n",
    "    --num_workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00384ef",
   "metadata": {},
   "source": [
    "Remove anything above context of pretrained model (hard generation limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f777016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('artifacts/challenge_set/clean.parquet')\n",
    "\n",
    "filtered_df = filter_df_to_context(\n",
    "    df,\n",
    "    context=1024,\n",
    "    cif_column=\"CIF\"\n",
    ")\n",
    "\n",
    "print(f\"Number of rows before filtering: {len(df)}\")\n",
    "print(f\"Number of rows after filtering: {len(filtered_df)}\")\n",
    "\n",
    "filtered_df.to_parquet('artifacts/challenge_set/clean_filtered.parquet', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68edbfd5",
   "metadata": {},
   "source": [
    "### Generating and Metrics - Composition prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2c9a5a",
   "metadata": {},
   "source": [
    "Make Prompts at level 3, with detailed composition info as per original benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34de889",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/make_prompts.py \\\n",
    "    --automatic \\\n",
    "    --input_df 'artifacts/challenge_set/clean_filtered.parquet' \\\n",
    "    --cif_column 'CIF' \\\n",
    "    --level 'level_3' \\\n",
    "    --output_parquet 'artifacts/challenge_set/challenge_prompt_test.parquet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d43c5",
   "metadata": {},
   "source": [
    "Generate the CIFs (T=0.7, K=10, 100 generation attempts) as per og benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a12a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/generate_CIFs.py \\\n",
    "    --config '_config_files/generation/unconditional/lematerial-challenge_eval.jsonc'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc715f0",
   "metadata": {},
   "source": [
    "Post process to retrieve standardised CIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d18eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_evaluation_og/postprocess.py \\\n",
    "    --input_parquet '_artifacts/challenge_set/gen_07T10K.parquet' \\\n",
    "    --output_parquet '_artifacts/challenge_set/gen_07T10K_processed.parquet' \\\n",
    "    --num_workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad49bc2",
   "metadata": {},
   "source": [
    "Calculate metrics (how many matches to true structs within the gen structs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1841a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_metrics/challenge_set_metrics.py \\\n",
    "    --input_parquet '_artifacts/challenge_set/gen_07T10K_processed.parquet' \\\n",
    "    --path_to_db '_artifacts/challenge_set/true_structs.parquet' \\\n",
    "    --num_gens 20 \\\n",
    "    --num_workers 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6d98d7",
   "metadata": {},
   "source": [
    "### Generation and prompting - Composition + Spacegroup Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3991531",
   "metadata": {},
   "source": [
    "Same as above but spacegroup info is included in the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadce7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/make_prompts.py \\\n",
    "    --automatic \\\n",
    "    --input_df '_artifacts/challenge_set/clean_filtered.parquet' \\\n",
    "    --cif_column 'CIF' \\\n",
    "    --level 'level_4' \\\n",
    "    --output_parquet 'artifacts/challenge_set/challenge_prompt_test_sg.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fb5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_generating/generate_CIFs.py \\\n",
    "    --config '_config_files/generation/unconditional/lematerial-challenge-sg_eval.jsonc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_evaluation_og/postprocess.py \\\n",
    "    --input_parquet '_artifacts/challenge_set/gen_sg_07T10K.parquet' \\\n",
    "    --output_parquet '_artifacts/challenge_set/gen_sg_07T10K_processed.parquet' \\\n",
    "    --num_workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python _utils/_metrics/challenge_set_metrics.py \\\n",
    "    --input_parquet '_artifacts/challenge_set/gen_sg_07T10K_processed.parquet' \\\n",
    "    --path_to_db '_artifacts/challenge_set/true_structs.parquet' \\\n",
    "    --num_gens 20 \\\n",
    "    --num_workers 16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crystallmv2_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
